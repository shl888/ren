"""
ç§äººHTTPæ•°æ®è·å–å™¨ - ä¸¥æ ¼é›¶ç¼“å­˜æ¨¡å¼
å®Œå…¨æ¨¡ä»¿private_ws_poolçš„æ¶æ„å’Œäº¤äº’æ–¹å¼
"""
import asyncio
import logging
import time
import hmac
import hashlib
import urllib.parse
import json
from datetime import datetime, timezone
from typing import Dict, Any, Optional, Set, List
import aiohttp

logger = logging.getLogger(__name__)


class PrivateHTTPFetcher:
    """
    ç§äººHTTPæ•°æ®è·å–å™¨
    æ¨¡ä»¿PrivateWebSocketPoolçš„æ¶æ„å’Œæ¥å£
    """

    def __init__(self):
        # ä¸private_ws_poolç›¸åŒçš„ç»“æ„
        self.brain_store = None  # DataManagerå®ä¾‹
        self.running = False

        # APIå‡­è¯ï¼ˆå¯åŠ¨æ—¶è·å–ä¸€æ¬¡ï¼‰
        self.api_key = None
        self.api_secret = None
        self.listen_key = None

        # ä»»åŠ¡ç®¡ç†
        self.scheduler_task = None
        self.fetch_tasks = []

        # Sessionå¤ç”¨ï¼ˆä¼˜åŒ–ï¼šé¿å…æ¯æ¬¡æ–°å»ºè¿æ¥ï¼‰
        self.session = None

        # çŠ¶æ€æ ‡å¿—
        self.account_fetched = False  # è´¦æˆ·æ˜¯å¦å·²è·å–
        self.account_fetch_success = False  # è´¦æˆ·è·å–æ˜¯å¦æˆåŠŸ

        # ğŸ”´ é‡è¯•ç­–ç•¥ï¼šæŒ‡æ•°é€€é¿
        self.account_retry_delays = [10, 20, 40, 60]  # å…±5æ¬¡å°è¯•ï¼ˆç¬¬1æ¬¡+4æ¬¡é‡è¯•ï¼‰
        self.max_account_retries = 4  # æœ€å¤šé‡è¯•4æ¬¡

        # ğŸ”´ ä¼˜åŒ–ï¼šè‡ªé€‚åº”é¢‘ç‡æ§åˆ¶ï¼ˆåº”ç”¨åˆ°è´¦æˆ·æ•°æ®ï¼‰
        self.account_check_interval = 1  # å½“å‰æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        self.account_high_freq = 1  # é«˜é¢‘ï¼š1ç§’ï¼ˆæœ‰æŒä»“æ—¶ï¼‰
        self.account_low_freq = 60  # ä½é¢‘ï¼š60ç§’ï¼ˆæ— æŒä»“æ—¶ï¼‰
        self.has_position = False  # å½“å‰æ˜¯å¦æœ‰æŒä»“
        self.last_log_time = 0  # ä¸Šæ¬¡æ—¥å¿—æ—¶é—´
        self.log_interval = 60  # æ—¥å¿—é—´éš”ï¼ˆç§’ï¼‰

        # è¿æ¥è´¨é‡ç»Ÿè®¡ï¼ˆæ¨¡ä»¿pool_managerï¼‰
        self.quality_stats = {
            'account_fetch': {
                'total_attempts': 0,
                'success_attempts': 0,
                'last_success': None,
                'last_error': None,
                'success_rate': 100.0,
                'retry_count': 0
            }
        }

        # ğŸ”´ å¸å®‰APIç«¯ç‚¹é…ç½®ï¼ˆæ¨¡æ‹Ÿäº¤æ˜“ vs çœŸå®äº¤æ˜“ï¼‰
        # å½“å‰å¯ç”¨ï¼šæ¨¡æ‹Ÿäº¤æ˜“ç«¯ç‚¹ï¼ˆTestnetï¼‰
        self.BASE_URL = "https://testnet.binancefuture.com"

        # çœŸå®äº¤æ˜“ç«¯ç‚¹ï¼ˆéœ€è¦ä½¿ç”¨æ—¶å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šï¼Œå¹¶æ³¨é‡Šæ‰ä¸Šé¢çš„æ¨¡æ‹Ÿç«¯ç‚¹ï¼‰
        # self.BASE_URL = "https://fapi.binance.com"

        self.ACCOUNT_ENDPOINT = "/fapi/v3/account"  # è´¦æˆ·èµ„äº§

        # ğŸ”´ ä¼˜åŒ–ï¼šæ·»åŠ recvWindowé…ç½®
        self.RECV_WINDOW = 5000  # 5ç§’æ¥æ”¶çª—å£

        # ğŸ”´ ä¼˜åŒ–ï¼šè®°å½•å½“å‰ä½¿ç”¨çš„ç¯å¢ƒ
        self.environment = "testnet" if "testnet" in self.BASE_URL else "live"
        
        # ğŸ”´ æ–°å¢ï¼šèµ„é‡‘è´¹æŸ¥è¯¢ç›¸å…³é…ç½®ï¼ˆç®€åŒ–ç‰ˆï¼‰
        self.INCOME_ENDPOINT = "/fapi/v1/income"  # èµ„é‡‘æµæ°´æ¥å£
        self.FUNDING_RETRY_INTERVAL = 10  # ğŸ”´ ä¿®æ”¹ï¼šæ¯10ç§’é‡è¯•ä¸€æ¬¡
        self.FUNDING_MAX_RETRIES = 5  # ğŸ”´ ä¿®æ”¹ï¼šå¼ºåˆ¶é‡è¯•5æ¬¡
        self.FUNDING_QUERY_WINDOW_MS = 300 * 1000  # 5åˆ†é’ŸæŸ¥è¯¢çª—å£
        self.FUNDING_INITIAL_DELAY = 30  # æ•´ç‚¹åå»¶è¿Ÿ30ç§’
        self.last_funding_trigger_hour = -1  # ä¸Šæ¬¡è§¦å‘èµ„é‡‘è´¹æŸ¥è¯¢çš„UTCå°æ—¶
        
        logger.info(
            f"ğŸ”— [HTTPè·å–å™¨] åˆå§‹åŒ–å®Œæˆï¼ˆç¯å¢ƒ: {self.environment} | è‡ªé€‚åº”é¢‘ç‡ | æ•´ç‚¹èµ„é‡‘è´¹æŸ¥è¯¢ | å¼ºåˆ¶é‡è¯•5æ¬¡ï¼‰")

    async def start(self, brain_store):
        """
        å¯åŠ¨è·å–å™¨ - ä¸¥æ ¼æŒ‰ç…§æ—¶åºæ§åˆ¶

        Args:
            brain_store: DataManagerå®ä¾‹ï¼ˆä¸ç§äººè¿æ¥æ± ç›¸åŒï¼‰
        """
        logger.info(f"ğŸš€ [HTTPè·å–å™¨] æ­£åœ¨å¯åŠ¨ï¼ˆç¯å¢ƒ: {self.environment} | è‡ªé€‚åº”é¢‘ç‡ï¼‰...")

        self.brain_store = brain_store
        self.running = True

        # ğŸ”´ ä¼˜åŒ–ï¼šåˆ›å»ºå¤ç”¨çš„ClientSession
        timeout = aiohttp.ClientTimeout(total=30)
        self.session = aiohttp.ClientSession(timeout=timeout)

        # åˆ›å»ºç»Ÿä¸€çš„è°ƒåº¦ä»»åŠ¡ï¼Œä¸¥æ ¼æ§åˆ¶æ—¶åº
        self.scheduler_task = asyncio.create_task(self._controlled_scheduler())

        logger.info("âœ… [HTTPè·å–å™¨] è°ƒåº¦å™¨å·²å¯åŠ¨ï¼Œç­‰å¾…4åˆ†é’Ÿåæ‰§è¡Œè´¦æˆ·è·å–")
        return True

    async def _controlled_scheduler(self):
        """
        å—æ§è°ƒåº¦å™¨ - ä¸¥æ ¼æŒ‰ç…§æ—¶é—´é¡ºåºæ‰§è¡Œ
        1. ç­‰å¾…4åˆ†é’Ÿï¼ˆè®©å…¶ä»–æ¨¡å—å…ˆè¿è¡Œï¼‰
        2. å°è¯•è·å–è´¦æˆ·èµ„äº§ï¼ˆ5æ¬¡æŒ‡æ•°é€€é¿é‡è¯•ï¼‰
        3. è´¦æˆ·æˆåŠŸåå¯åŠ¨è‡ªé€‚åº”é¢‘ç‡çš„è´¦æˆ·æ•°æ®è·å–ä»»åŠ¡
        """
        try:
            # ========== ç¬¬ä¸€é˜¶æ®µï¼šç­‰å¾…4åˆ†é’Ÿ ==========
            logger.info("â³ [HTTPè·å–å™¨] ç¬¬ä¸€é˜¶æ®µï¼šç­‰å¾…4åˆ†é’Ÿï¼Œè®©å…¶ä»–æ¨¡å—å…ˆè¿è¡Œ...")
            for i in range(240):  # 240ç§’ = 4åˆ†é’Ÿ
                if not self.running:
                    return
                if i % 60 == 0:  # æ¯åˆ†é’Ÿè®°å½•ä¸€æ¬¡
                    remaining = 240 - i
                    logger.info(f"â³ [HTTPè·å–å™¨] ç­‰å¾…ä¸­...å‰©ä½™{remaining}ç§’")
                await asyncio.sleep(1)

            logger.info("âœ… [HTTPè·å–å™¨] 4åˆ†é’Ÿç­‰å¾…å®Œæˆï¼Œå¼€å§‹è´¦æˆ·è·å–ï¼ˆ5æ¬¡å°è¯•ï¼‰")

            # ========== ç¬¬äºŒé˜¶æ®µï¼šè·å–è´¦æˆ·èµ„äº§ï¼ˆ5æ¬¡æŒ‡æ•°é€€é¿é‡è¯•ï¼‰ ==========
            self.account_fetch_success = await self._fetch_account_with_retry()

            if self.account_fetch_success:
                logger.info("âœ… [HTTPè·å–å™¨] è´¦æˆ·è·å–æˆåŠŸï¼Œå¯åŠ¨è‡ªé€‚åº”é¢‘ç‡çš„è´¦æˆ·æ•°æ®è·å–ä»»åŠ¡")

                # ========== ç¬¬ä¸‰é˜¶æ®µï¼šå¯åŠ¨è‡ªé€‚åº”é¢‘ç‡çš„è´¦æˆ·æ•°æ®è·å– ==========
                # å†ç­‰å¾…30ç§’ï¼Œç¡®ä¿å®Œå…¨å†·å´
                logger.info("â³ [HTTPè·å–å™¨] è´¦æˆ·æˆåŠŸåå†·å´30ç§’...")
                await asyncio.sleep(30)

                # ğŸ”´ ä¿®æ”¹ï¼šå¯åŠ¨è‡ªé€‚åº”é¢‘ç‡çš„è´¦æˆ·æ•°æ®è·å–ä»»åŠ¡
                account_task = asyncio.create_task(
                    self._fetch_account_adaptive_freq())
                self.fetch_tasks.append(account_task)
                logger.info(
                    "âœ… [HTTPè·å–å™¨] è‡ªé€‚åº”é¢‘ç‡è´¦æˆ·æ•°æ®è·å–å·²å¯åŠ¨ï¼ˆæœ‰æŒä»“1ç§’/æ— æŒä»“60ç§’ + æ•´ç‚¹èµ„é‡‘è´¹æŸ¥è¯¢ï¼‰")
            else:
                logger.warning("âš ï¸ [HTTPè·å–å™¨] è´¦æˆ·è·å–5æ¬¡å°è¯•å‡å¤±è´¥ï¼Œä¸å¯åŠ¨åç»­ä»»åŠ¡")

        except asyncio.CancelledError:
            logger.info("ğŸ›‘ [HTTPè·å–å™¨] è°ƒåº¦å™¨è¢«å–æ¶ˆ")
        except Exception as e:
            logger.error(f"âŒ [HTTPè·å–å™¨] è°ƒåº¦å™¨å¼‚å¸¸: {e}")

    async def _fetch_account_with_retry(self):
        """
        è·å–è´¦æˆ·èµ„äº§ - 5æ¬¡æŒ‡æ•°é€€é¿é‡è¯•
        ç¬¬1æ¬¡å°è¯• + 4æ¬¡é‡è¯•ï¼ˆ10ç§’, 20ç§’, 40ç§’, 60ç§’åï¼‰

        ğŸ”´ å…³é”®ä¿®å¤ï¼š418/401é”™è¯¯ç«‹å³åœæ­¢ï¼Œä¸å†é‡è¯•
        """
        retry_count = 0
        total_attempts = 0

        # ç¬¬1æ¬¡å°è¯•ï¼ˆç«‹å³æ‰§è¡Œï¼‰
        logger.info(f"ğŸ’° [HTTPè·å–å™¨] è´¦æˆ·è·å–ç¬¬1æ¬¡å°è¯•...")
        result = await self._fetch_account_single()
        total_attempts += 1

        # ğŸ”´ ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦é‡åˆ°418ï¼ˆIPå°ç¦ï¼‰æˆ–401ï¼ˆæƒé™é”™è¯¯ï¼‰
        if result == 'PERMANENT_STOP':
            logger.error("ğŸš¨ [HTTPè·å–å™¨] é‡åˆ°ä¸å¯é€†é”™è¯¯ï¼ˆ418/401ï¼‰ï¼Œåœæ­¢æ‰€æœ‰é‡è¯•")
            self.quality_stats['account_fetch']['retry_count'] = 0
            return False

        if result == True:
            self.quality_stats['account_fetch']['retry_count'] = 0
            return True

        # 4æ¬¡é‡è¯•ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
        while retry_count < self.max_account_retries and self.running:
            delay = self.account_retry_delays[retry_count]
            logger.info(
                f"â³ [HTTPè·å–å™¨] {delay}ç§’åé‡è¯•è´¦æˆ·è·å–ï¼ˆç¬¬{retry_count + 2}æ¬¡å°è¯•ï¼‰...")
            await asyncio.sleep(delay)

            logger.info(f"ğŸ’° [HTTPè·å–å™¨] è´¦æˆ·è·å–ç¬¬{retry_count + 2}æ¬¡å°è¯•...")
            result = await self._fetch_account_single()
            total_attempts += 1
            retry_count += 1

            # ğŸ”´ ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦é‡åˆ°418æˆ–401
            if result == 'PERMANENT_STOP':
                logger.error(
                    f"ğŸš¨ [HTTPè·å–å™¨] ç¬¬{retry_count}æ¬¡å°è¯•é‡åˆ°ä¸å¯é€†é”™è¯¯ï¼Œåœæ­¢é‡è¯•")
                self.quality_stats['account_fetch']['retry_count'] = retry_count
                return False

            if result == True:
                self.quality_stats['account_fetch']['retry_count'] = retry_count
                return True

        # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
        self.quality_stats['account_fetch']['retry_count'] = retry_count
        logger.error(f"âŒ [HTTPè·å–å™¨] è´¦æˆ·è·å–{total_attempts}æ¬¡å°è¯•å…¨éƒ¨å¤±è´¥")
        return False

    async def _fetch_account_single(self):
        """
        å•æ¬¡å°è¯•è·å–è´¦æˆ·èµ„äº§ï¼ˆä¼˜åŒ–ç‰ˆï¼šæ·»åŠ recvWindowï¼‰

        Returns:
            True: æˆåŠŸ
            False: å¤±è´¥ï¼Œå¯é‡è¯•
            'PERMANENT_STOP': é‡åˆ°ä¸å¯é€†é”™è¯¯ï¼ˆ418/401ï¼‰ï¼Œåœæ­¢æ‰€æœ‰é‡è¯•
        """
        try:
            self.quality_stats['account_fetch']['total_attempts'] += 1

            api_key, api_secret = await self._get_fresh_credentials()
            if not api_key or not api_secret:
                logger.warning("âš ï¸ [HTTPè·å–å™¨] å‡­è¯è¯»å–å¤±è´¥ï¼Œæœ¬æ¬¡å°è¯•è·³è¿‡")
                self.quality_stats['account_fetch']['last_error'] = "å‡­è¯è¯»å–å¤±è´¥"
                return False

            # ğŸ”´ ä¼˜åŒ–ï¼šæ·»åŠ recvWindowå‚æ•°ï¼ˆå¸å®‰APIè¦æ±‚ï¼‰
            params = {
                'timestamp': int(time.time() * 1000),
                'recvWindow': self.RECV_WINDOW  # 5000ms
            }
            signed_params = self._sign_params(params, api_secret)
            url = f"{self.BASE_URL}{self.ACCOUNT_ENDPOINT}"

            headers = {'X-MBX-APIKEY': api_key}

            # ğŸ”´ ä¼˜åŒ–ï¼šä½¿ç”¨å¤ç”¨çš„session
            async with self.session.get(url, params=signed_params, headers=headers) as resp:

                if resp.status == 200:
                    data = await resp.json()
                    await self._push_data('http_account', data)

                    self.quality_stats['account_fetch']['success_attempts'] += 1
                    self.quality_stats['account_fetch']['last_success'] = datetime.now(
                    ).isoformat()
                    self.quality_stats['account_fetch']['last_error'] = None
                    self.quality_stats['account_fetch']['success_rate'] = (
                        self.quality_stats['account_fetch']['success_attempts'] /
                        self.quality_stats['account_fetch']['total_attempts'] * 100
                    )

                    logger.info("âœ… [HTTPè·å–å™¨] è´¦æˆ·èµ„äº§è·å–æˆåŠŸï¼")
                    self.account_fetched = True
                    return True

                else:
                    error_text = await resp.text()
                    error_msg = f"HTTP {resp.status}: {error_text[:100]}"
                    self.quality_stats['account_fetch']['last_error'] = error_msg

                    # ğŸ”´ å…³é”®ä¿®å¤ï¼š418ï¼ˆIPå°ç¦ï¼‰- ç«‹å³åœæ­¢æ‰€æœ‰é‡è¯•
                    if resp.status == 418:
                        retry_after = int(resp.headers.get('Retry-After', 10))
                        logger.error(
                            f"ğŸš¨ [HTTPè·å–å™¨] IPè¢«å°ç¦(418)ï¼Œéœ€ç­‰å¾…{retry_after}ç§’")
                        # ğŸ”´ ä¿®å¤ï¼šè¿”å›ç‰¹æ®Šæ ‡è®°ï¼Œè®©ä¸Šå±‚çŸ¥é“è¦åœæ­¢æ‰€æœ‰é‡è¯•
                        return 'PERMANENT_STOP'

                    # ğŸ”´ å…³é”®ä¿®å¤ï¼š401ï¼ˆAPIå¯†é’¥æ— æ•ˆæˆ–æƒé™ä¸è¶³ï¼‰- ç«‹å³åœæ­¢
                    if resp.status == 401:
                        logger.error(
                            f"ğŸš¨ [HTTPè·å–å™¨] APIå¯†é’¥æ— æ•ˆæˆ–æƒé™ä¸è¶³(401)")
                        logger.error(f"   å½“å‰ç¯å¢ƒ: {self.environment}")
                        logger.error(f"   è¯·æ£€æŸ¥ï¼š")
                        logger.error(
                            f"   1. APIå¯†é’¥æ˜¯å¦åŒ¹é…å½“å‰ç¯å¢ƒï¼ˆæ¨¡æ‹Ÿ/çœŸå®ï¼‰")
                        logger.error(
                            f"   2. APIå¯†é’¥æ˜¯å¦å¯ç”¨äº†åˆçº¦æƒé™")
                        logger.error(f"   3. IPç™½åå•æ˜¯å¦æ­£ç¡®")
                        return 'PERMANENT_STOP'

                    # ğŸ”´ ä¼˜åŒ–ï¼š429ï¼ˆé¢‘ç‡é™åˆ¶ï¼‰- ç­‰å¾…åé‡è¯•
                    if resp.status == 429:
                        retry_after = int(resp.headers.get('Retry-After', 60))
                        logger.warning(
                            f"âš ï¸ [HTTPè·å–å™¨] è§¦å‘é¢‘ç‡é™åˆ¶(429)ï¼Œç­‰å¾…{retry_after}ç§’åé‡è¯•")
                        await asyncio.sleep(retry_after)
                        return False

                    logger.error(f"âŒ [HTTPè·å–å™¨] è´¦æˆ·è¯·æ±‚å¤±è´¥ {error_msg}")
                    return False

        except asyncio.TimeoutError:
            error_msg = "è¯·æ±‚è¶…æ—¶"
            self.quality_stats['account_fetch']['last_error'] = error_msg
            logger.error(f"â±ï¸ [HTTPè·å–å™¨] è´¦æˆ·è¯·æ±‚è¶…æ—¶")
            return False
        except Exception as e:
            error_msg = str(e)
            self.quality_stats['account_fetch']['last_error'] = error_msg
            logger.error(f"âŒ [HTTPè·å–å™¨] è·å–è´¦æˆ·å¼‚å¸¸: {e}")
            return False

    async def _fetch_account_adaptive_freq(self):
        """
        è‡ªé€‚åº”é¢‘ç‡è·å–è´¦æˆ·æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼šæœ‰æŒä»“1ç§’/æ— æŒä»“60ç§’ + æ—¥å¿—æ§åˆ¶ï¼‰
        ä»è´¦æˆ·æ•°æ®æœ¬èº«çš„positionså­—æ®µåˆ¤æ–­æ˜¯å¦æœ‰æŒä»“
        """
        request_count = 0

        # åˆå§‹ç­‰å¾…
        await asyncio.sleep(30)

        while self.running:
            try:
                request_count += 1

                api_key, api_secret = await self._get_fresh_credentials()
                if not api_key or not api_secret:
                    logger.warning("âš ï¸ [HTTPè·å–å™¨] è´¦æˆ·è¯·æ±‚-å‡­è¯è¯»å–å¤±è´¥")
                    await asyncio.sleep(self.account_check_interval)
                    continue

                # ğŸ”´ ä¼˜åŒ–ï¼šæ·»åŠ recvWindowå‚æ•°
                params = {
                    'timestamp': int(time.time() * 1000),
                    'recvWindow': self.RECV_WINDOW  # 5000ms
                }
                signed_params = self._sign_params(params, api_secret)
                url = f"{self.BASE_URL}{self.ACCOUNT_ENDPOINT}"

                headers = {'X-MBX-APIKEY': api_key}

                # ğŸ”´ ä¼˜åŒ–ï¼šä½¿ç”¨å¤ç”¨çš„session
                async with self.session.get(url, params=signed_params, headers=headers) as resp:

                    if resp.status == 200:
                        data = await resp.json()

                        # ğŸ”´ å…³é”®ï¼šæ£€æŸ¥è´¦æˆ·æ•°æ®ä¸­æ˜¯å¦æœ‰æŒä»“
                        positions = data.get('positions', [])
                        # è¿‡æ»¤æ‰ä»“ä½ä¸º0çš„æŒä»“
                        has_position_now = False
                        active_symbols = set()  # ğŸ”´ æ–°å¢ï¼šè®°å½•æ´»è·ƒåˆçº¦ç¬¦å·
                        for pos in positions:
                            position_amt = float(pos.get('positionAmt', '0'))
                            if position_amt != 0:  # ä»“ä½ä¸ä¸º0è¡¨ç¤ºæœ‰çœŸå®æŒä»“
                                has_position_now = True
                                active_symbols.add(pos['symbol'])  # ğŸ”´ æ–°å¢ï¼šè®°å½•ç¬¦å·
                        
                        # ğŸ”´ æ–°å¢ï¼šæ•´ç‚¹èµ„é‡‘è´¹æŸ¥è¯¢è§¦å‘
                        await self._trigger_funding_fetch_if_needed(
                            api_key, api_secret, has_position_now, active_symbols
                        )

                        # ğŸ”´ è‡ªé€‚åº”é¢‘ç‡è°ƒæ•´
                        if has_position_now:
                            # æœ‰æŒä»“ â†’ é«˜é¢‘æ¨¡å¼ï¼ˆ1ç§’ï¼‰
                            if not self.has_position:
                                # çŠ¶æ€å˜åŒ–ï¼šä»æ— æŒä»“å˜ä¸ºæœ‰æŒä»“
                                logger.info(
                                    f"ğŸš€ [HTTPè·å–å™¨] æ£€æµ‹åˆ°æŒä»“ï¼Œåˆ‡æ¢é«˜é¢‘æ¨¡å¼ï¼ˆ1ç§’ï¼‰")
                            self.account_check_interval = self.account_high_freq
                            self.has_position = True
                        else:
                            # æ— æŒä»“ â†’ ä½é¢‘æ¨¡å¼ï¼ˆ60ç§’ï¼‰
                            if self.has_position:
                                # çŠ¶æ€å˜åŒ–ï¼šä»æœ‰æŒä»“å˜ä¸ºæ— æŒä»“
                                logger.info(
                                    f"ğŸ’¤ [HTTPè·å–å™¨] æ£€æµ‹åˆ°æ¸…ä»“ï¼Œåˆ‡æ¢ä½é¢‘æ¨¡å¼ï¼ˆ60ç§’ï¼‰")
                            self.account_check_interval = self.account_low_freq
                            self.has_position = False

                        # ğŸ”´ ä¼˜åŒ–ï¼šæ—¥å¿—æ§åˆ¶ï¼ˆæ¯åˆ†é’Ÿåªæ‰“å°1æ¬¡ï¼‰
                        current_time = time.time()
                        if current_time - self.last_log_time >= self.log_interval:
                            if has_position_now:
                                positions_count = len(active_symbols)  # ğŸ”´ ä¿®æ”¹ï¼šä½¿ç”¨å·²è®¡ç®—çš„æ´»è·ƒæ•°é‡
                                logger.info(
                                    f"ğŸ“Š [HTTPè·å–å™¨] å½“å‰æŒä»“{positions_count}ä¸ª | é«˜é¢‘æ¨¡å¼ | è¯·æ±‚æ¬¡æ•°:{request_count}")
                            else:
                                logger.info(
                                    f"ğŸ“Š [HTTPè·å–å™¨] å½“å‰æ— æŒä»“ | ä½é¢‘æ¨¡å¼ | è¯·æ±‚æ¬¡æ•°:{request_count}")
                            self.last_log_time = current_time

                        await self._push_data('http_account', data)

                        self.quality_stats['account_fetch']['success_attempts'] += 1
                        self.quality_stats['account_fetch']['total_attempts'] += 1
                        self.quality_stats['account_fetch']['last_success'] = datetime.now(
                        ).isoformat()
                        self.quality_stats['account_fetch']['last_error'] = None
                        self.quality_stats['account_fetch']['success_rate'] = (
                            self.quality_stats['account_fetch']['success_attempts'] /
                            self.quality_stats['account_fetch']['total_attempts'] * 100
                        )

                        # æŒ‰å½“å‰é¢‘ç‡ç­‰å¾…
                        await asyncio.sleep(self.account_check_interval)

                    else:
                        error_text = await resp.text()
                        error_msg = f"HTTP {resp.status}: {error_text[:100]}"
                        self.quality_stats['account_fetch']['last_error'] = error_msg
                        logger.error(f"âŒ [HTTPè·å–å™¨] è´¦æˆ·è¯·æ±‚å¤±è´¥ {error_msg}")

                        # ğŸ”´ ä¼˜åŒ–ï¼šæ­£ç¡®å¤„ç†418å’Œ401ï¼ˆæ°¸ä¹…åœæ­¢ï¼‰
                        if resp.status in [418, 401]:
                            retry_after = int(
                                resp.headers.get('Retry-After', 3600))
                            logger.error(
                                f"ğŸš¨ [HTTPè·å–å™¨] è´¦æˆ·è¯·æ±‚è§¦å‘ä¸¥é‡é”™è¯¯({resp.status})ï¼Œç­‰å¾…{retry_after}ç§’åæ°¸ä¹…åœæ­¢")
                            await asyncio.sleep(retry_after)
                            # è´¦æˆ·ä»»åŠ¡é‡åˆ°418/401ä¹Ÿåœæ­¢
                            logger.error(f"ğŸš¨ [HTTPè·å–å™¨] è´¦æˆ·ä»»åŠ¡æ°¸ä¹…åœæ­¢")
                            break

                        # ğŸ”´ ä¼˜åŒ–ï¼šæ­£ç¡®å¤„ç†429
                        if resp.status == 429:
                            retry_after = int(
                                resp.headers.get('Retry-After', 60))
                            logger.warning(
                                f"âš ï¸ [HTTPè·å–å™¨] è´¦æˆ·è¯·æ±‚è§¦å‘é¢‘ç‡é™åˆ¶(429)ï¼Œç­‰å¾…{retry_after}ç§’")
                            await asyncio.sleep(retry_after)
                        else:
                            await asyncio.sleep(self.account_check_interval)

            except asyncio.CancelledError:
                break
            except Exception as e:
                error_msg = str(e)
                self.quality_stats['account_fetch']['last_error'] = error_msg
                logger.error(f"âŒ [HTTPè·å–å™¨] è´¦æˆ·å¾ªç¯å¼‚å¸¸: {e}")
                await asyncio.sleep(self.account_check_interval)

    async def _trigger_funding_fetch_if_needed(self, api_key: str, api_secret: str, 
                                              has_position: bool, active_symbols: Set[str]):
        """
        åœ¨æ•´ç‚¹è§¦å‘èµ„é‡‘è´¹æŸ¥è¯¢ã€‚
        è§„åˆ™ï¼šæ¯ä¸ªUTCæ•´ç‚¹ï¼Œå¦‚æœæœ‰æŒä»“ï¼Œåˆ™åœ¨æ•´ç‚¹åå»¶è¿Ÿ30ç§’å¯åŠ¨æŸ¥è¯¢ä»»åŠ¡ã€‚
        """
        if not has_position:
            # æ— æŒä»“ï¼Œæ— éœ€è§¦å‘ï¼Œå¹¶é‡ç½®è§¦å‘æ ‡è®°
            self.last_funding_trigger_hour = -1
            return

        # è·å–å½“å‰UTCæ—¶é—´
        utc_now = datetime.now(timezone.utc)
        current_hour = utc_now.hour

        # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨æœ¬å°æ—¶è§¦å‘è¿‡
        if current_hour == self.last_funding_trigger_hour:
            return

        # è®¡ç®—ä»å½“å‰æ—¶é—´åˆ°æ•´ç‚¹å·²è¿‡å»çš„ç§’æ•°
        minutes_into_hour = utc_now.minute
        seconds_into_hour = minutes_into_hour * 60 + utc_now.second

        # åªåœ¨æ•´ç‚¹åçš„æœ€åˆ1åˆ†é’Ÿå†…è¿›è¡Œåˆ¤æ–­å’Œå¯åŠ¨ï¼Œé¿å…åœ¨å°æ—¶ä¸­æ®µè¯¯è§¦å‘
        if seconds_into_hour > 60:
            return

        # è®°å½•è§¦å‘æ—¶é—´ï¼Œé¿å…æœ¬å°æ—¶å†…é‡å¤è§¦å‘
        self.last_funding_trigger_hour = current_hour
        logger.info(f"ğŸ• [èµ„é‡‘è´¹] åœ¨UTC {current_hour:02d}:00:00 æ£€æµ‹åˆ°æŒä»“ï¼Œå‡†å¤‡è§¦å‘æŸ¥è¯¢...")

        # å»¶è¿Ÿ30ç§’åå¯åŠ¨ç‹¬ç«‹çš„èµ„é‡‘è´¹æŸ¥è¯¢ä»»åŠ¡
        asyncio.create_task(
            self._execute_funding_fetch_task(api_key, api_secret, active_symbols, utc_now)
        )

    async def _execute_funding_fetch_task(self, api_key: str, api_secret: str, 
                                         active_symbols: Set[str], trigger_time: datetime):
        """
        æ‰§è¡Œèµ„é‡‘è´¹æŸ¥è¯¢ä»»åŠ¡ - ç®€åŒ–ç‰ˆï¼šå¼ºåˆ¶é‡è¯•5æ¬¡ï¼Œç›´æ¥æ¨é€æ•°æ®
        """
        await asyncio.sleep(self.FUNDING_INITIAL_DELAY)

        logger.info(f"ğŸš€ [èµ„é‡‘è´¹] å¼€å§‹æ‰§è¡Œèµ„é‡‘è´¹æŸ¥è¯¢ä»»åŠ¡ï¼Œæ´»è·ƒåˆçº¦: {active_symbols}")
        logger.info(f"ğŸ” [èµ„é‡‘è´¹] ç­–ç•¥ï¼šå¼ºåˆ¶é‡è¯•5æ¬¡ï¼Œæ¯10ç§’ä¸€æ¬¡ï¼Œä¸éªŒè¯æ•°æ®å®Œæ•´æ€§")

        retry_count = 0
        max_attempts = self.FUNDING_MAX_RETRIES  # 5æ¬¡é‡è¯•

        while retry_count < max_attempts and self.running:
            attempt_num = retry_count + 1
            logger.info(f"ğŸ”„ [èµ„é‡‘è´¹] ç¬¬{attempt_num}æ¬¡å°è¯•ï¼ˆå…±{max_attempts}æ¬¡ï¼‰")

            success, income_data = await self._fetch_funding_income_single(
                api_key, api_secret, trigger_time
            )

            if success:
                # ğŸ”´ å…³é”®ä¿®æ”¹ï¼šæ— è®ºæ•°æ®æ˜¯å¦å®Œæ•´ï¼Œéƒ½ç›´æ¥æ¨é€
                logger.info(f"âœ… [èµ„é‡‘è´¹] ç¬¬{attempt_num}æ¬¡å°è¯•è·å–åˆ°æ•°æ®ï¼Œç«‹å³æ¨é€")
                
                # æ‰“å°åŸå§‹æ•°æ®ä»¥ä¾¿è°ƒè¯•
                if income_data:
                    logger.info(f"ğŸ“Š [èµ„é‡‘è´¹] è·å–åˆ°{len(income_data)}æ¡è®°å½•")
                    # æ‰“å°å‰å‡ æ¡è®°å½•
                    for i, record in enumerate(income_data[:3]):
                        logger.info(f"ğŸ“Š [èµ„é‡‘è´¹] è®°å½•{i+1}: {record}")
                
                # ç›´æ¥æ¨é€åŸå§‹æ•°æ®
                await self._push_data('http_funding_income', {
                    'trigger_time': trigger_time.isoformat(),
                    'attempt_number': attempt_num,
                    'total_attempts': max_attempts,
                    'active_symbols': list(active_symbols),
                    'income_data': income_data if income_data else [],
                    'status': 'success' if income_data else 'empty'
                })
                
                logger.info(f"âœ… [èµ„é‡‘è´¹] ç¬¬{attempt_num}æ¬¡æ•°æ®å·²æ¨é€")
                
                # ğŸ”´ ç«‹å³ç»§ç»­ä¸‹ä¸€æ¬¡å°è¯•ï¼Œä¸ç­‰å¾…
                retry_count += 1
                if retry_count < max_attempts:
                    logger.info(f"â³ [èµ„é‡‘è´¹] ç­‰å¾…{self.FUNDING_RETRY_INTERVAL}ç§’åç»§ç»­ä¸‹ä¸€æ¬¡å°è¯•...")
                    await asyncio.sleep(self.FUNDING_RETRY_INTERVAL)
                else:
                    logger.info(f"âœ… [èµ„é‡‘è´¹] å·²å®Œæˆå…¨éƒ¨{max_attempts}æ¬¡å°è¯•")
            else:
                # è¯·æ±‚å¤±è´¥
                logger.warning(f"âš ï¸ [èµ„é‡‘è´¹] ç¬¬{attempt_num}æ¬¡å°è¯•å¤±è´¥")
                
                # å³ä½¿å¤±è´¥ä¹Ÿæ¨é€ç©ºæ•°æ®ç”¨äºè®°å½•
                await self._push_data('http_funding_income', {
                    'trigger_time': trigger_time.isoformat(),
                    'attempt_number': attempt_num,
                    'total_attempts': max_attempts,
                    'active_symbols': list(active_symbols),
                    'income_data': [],
                    'status': 'failed'
                })
                
                retry_count += 1
                if retry_count < max_attempts:
                    logger.info(f"â³ [èµ„é‡‘è´¹] ç­‰å¾…{self.FUNDING_RETRY_INTERVAL}ç§’åç»§ç»­ä¸‹ä¸€æ¬¡å°è¯•...")
                    await asyncio.sleep(self.FUNDING_RETRY_INTERVAL)

        logger.info(f"âœ… [èµ„é‡‘è´¹] ä»»åŠ¡å®Œæˆï¼šæ‰§è¡Œäº†{retry_count}æ¬¡å°è¯•")

    async def _fetch_funding_income_single(self, api_key: str, api_secret: str, 
                                          trigger_time: datetime):
        """
        å•æ¬¡è·å–èµ„é‡‘è´¹å†å²è®°å½•
        ğŸ”´ ç®€åŒ–ç‰ˆï¼šä¸éªŒè¯æ•°æ®ï¼Œç›´æ¥è¿”å›
        """
        try:
            current_time_ms = int(time.time() * 1000)
            window_start_ms = current_time_ms - self.FUNDING_QUERY_WINDOW_MS

            # ğŸ”´ æµ‹è¯•ï¼šå»æ‰incomeTypeé™åˆ¶ï¼ŒæŸ¥çœ‹æ‰€æœ‰ç±»å‹çš„è®°å½•
            params = {
                'timestamp': current_time_ms,
                'recvWindow': self.RECV_WINDOW,
                # 'incomeType': 'FUNDING_FEE',  # å…ˆæ³¨é‡Šæ‰ï¼ŒæŸ¥çœ‹æ‰€æœ‰ç±»å‹
                'startTime': window_start_ms,
                'limit': 100
            }

            signed_params = self._sign_params(params, api_secret)
            url = f"{self.BASE_URL}{self.INCOME_ENDPOINT}"
            headers = {'X-MBX-APIKEY': api_key}

            # ğŸ”´ æ·»åŠ è¯¦ç»†è¯·æ±‚æ—¥å¿—
            logger.info(f"ğŸ” [èµ„é‡‘è´¹] å‘é€è¯·æ±‚åˆ°: {url}")
            logger.info(f"ğŸ” [èµ„é‡‘è´¹] æŸ¥è¯¢å‚æ•°: timestamp={params['timestamp']}, "
                       f"startTime={params['startTime']}")

            async with self.session.get(url, params=signed_params, headers=headers) as resp:
                response_text = await resp.text()
                
                if resp.status == 200:
                    try:
                        data = json.loads(response_text)
                        logger.info(f"ğŸ” [èµ„é‡‘è´¹] è¯·æ±‚æˆåŠŸï¼ŒçŠ¶æ€ç : {resp.status}")
                        return True, data
                    except json.JSONDecodeError as e:
                        logger.error(f"âŒ [èµ„é‡‘è´¹] JSONè§£æå¤±è´¥: {e}")
                        logger.error(f"âŒ [èµ„é‡‘è´¹] å“åº”å†…å®¹: {response_text[:200]}")
                        return False, None
                else:
                    logger.error(f"âŒ [èµ„é‡‘è´¹] è¯·æ±‚å¤±è´¥: HTTP {resp.status}")
                    logger.error(f"âŒ [èµ„é‡‘è´¹] å“åº”å†…å®¹: {response_text[:200]}")
                    return False, None

        except asyncio.TimeoutError:
            logger.error(f"â±ï¸ [èµ„é‡‘è´¹] è¯·æ±‚è¶…æ—¶")
            return False, None
        except Exception as e:
            logger.error(f"âŒ [èµ„é‡‘è´¹] è¯·æ±‚å¼‚å¸¸: {e}")
            return False, None

    async def on_listen_key_updated(self, exchange: str, listen_key: str):
        """æ¥æ”¶listenKeyæ›´æ–°ï¼ˆä¿ç•™æƒé™ï¼Œä»¥å¤‡ä¸æ—¶ä¹‹éœ€ï¼‰"""
        if exchange == 'binance':
            logger.debug(
                f"ğŸ“¢ [HTTPè·å–å™¨] æ”¶åˆ°{exchange} listenKeyæ›´æ–°é€šçŸ¥")
            # å¯ä»¥åœ¨è¿™é‡Œæ›´æ–°listen_keyï¼Œä½†HTTPè¯·æ±‚ä¸ä½¿ç”¨å®ƒ
            # self.listen_key = listen_key

    async def _get_fresh_credentials(self):
        """æ¯æ¬¡ä»å¤§è„‘è¯»å–æ–°é²œå‡­è¯ï¼ˆæ ¸å¿ƒï¼šé›¶ç¼“å­˜ï¼‰"""
        try:
            if not self.brain_store:
                return None, None
            creds = await self.brain_store.get_api_credentials('binance')
            if creds and creds.get('api_key') and creds.get('api_secret'):
                return creds['api_key'], creds['api_secret']
        except Exception as e:
            logger.error(f"âŒ [HTTPè·å–å™¨] è¯»å–å‡­è¯å¤±è´¥: {e}")
        return None, None

    def _sign_params(self, params: Dict, api_secret: str) -> Dict:
        """ç”Ÿæˆç­¾åï¼ˆå¸å®‰APIè¦æ±‚ï¼‰"""
        query = urllib.parse.urlencode(params)
        signature = hmac.new(api_secret.encode(),
                             query.encode(), hashlib.sha256).hexdigest()
        params['signature'] = signature
        return params

    async def _push_data(self, data_type: str, raw_data: Dict):
        """æ¨é€åŸå§‹æ•°æ®åˆ°å¤„ç†æ¨¡å—ï¼ˆä¸å¤„ç†ï¼‰"""
        try:
            from private_data_processing.manager import receive_private_data
            await receive_private_data({
                'exchange': 'binance',
                'data_type': data_type,
                'data': raw_data,
                'timestamp': datetime.now().isoformat(),
                'source': 'http_fetcher'
            })
        except ImportError as e:
            logger.error(f"âŒ [HTTPè·å–å™¨] æ— æ³•å¯¼å…¥ç§äººæ•°æ®å¤„ç†æ¨¡å—: {e}")
        except Exception as e:
            logger.error(f"âŒ [HTTPè·å–å™¨] æ¨é€æ•°æ®å¤±è´¥: {e}")

    async def shutdown(self):
        """å…³é—­è·å–å™¨ - æ¨¡ä»¿pool_manager.shutdown()"""
        logger.info("ğŸ›‘ [HTTPè·å–å™¨] æ­£åœ¨å…³é—­...")
        self.running = False

        # å–æ¶ˆè°ƒåº¦ä»»åŠ¡
        if self.scheduler_task:
            self.scheduler_task.cancel()
            try:
                await self.scheduler_task
            except asyncio.CancelledError:
                pass

        # å–æ¶ˆæ‰€æœ‰è·å–ä»»åŠ¡
        for task in self.fetch_tasks:
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass

        # ğŸ”´ ä¼˜åŒ–ï¼šå…³é—­å¤ç”¨çš„session
        if self.session:
            await self.session.close()
            logger.info("âœ… [HTTPè·å–å™¨] HTTPä¼šè¯å·²å…³é—­")

        logger.info("âœ… [HTTPè·å–å™¨] å·²å…³é—­")

    def get_status(self) -> Dict[str, Any]:
        """
        è·å–çŠ¶æ€ä¿¡æ¯ - æ¨¡ä»¿pool_manager.get_status()

        Returns:
            çŠ¶æ€å­—å…¸
        """
        status = {
            'timestamp': datetime.now().isoformat(),
            'running': self.running,
            'account_fetched': self.account_fetched,
            'account_fetch_success': self.account_fetch_success,
            'environment': self.environment,
            'adaptive_frequency': {
                'current_interval': self.account_check_interval,
                'has_position': self.has_position,
                'high_freq': self.account_high_freq,
                'low_freq': self.account_low_freq
            },
            'funding_fetch': {
                'enabled': True,
                'trigger_hour': self.last_funding_trigger_hour,
                'initial_delay': self.FUNDING_INITIAL_DELAY,
                'query_window_ms': self.FUNDING_QUERY_WINDOW_MS,
                'max_retries': self.FUNDING_MAX_RETRIES,
                'retry_interval': self.FUNDING_RETRY_INTERVAL,
                'strategy': 'å¼ºåˆ¶é‡è¯•5æ¬¡ï¼Œæ¯10ç§’ä¸€æ¬¡ï¼Œç›´æ¥æ¨é€æ•°æ®ä¸éªŒè¯'
            },
            'quality_stats': self.quality_stats,
            'retry_strategy': {
                'account_retries': f"{self.max_account_retries}æ¬¡é‡è¯•",
                'retry_delays': self.account_retry_delays,
                'total_attempts': self.max_account_retries + 1
            },
            'api_config': {
                'recvWindow': self.RECV_WINDOW,
                'session_reuse': True
            },
            'schedule': {
                'account': 'å¯åŠ¨å4åˆ†é’Ÿå¼€å§‹ï¼Œ5æ¬¡æŒ‡æ•°é€€é¿é‡è¯•ï¼Œç„¶åè‡ªé€‚åº”é¢‘ç‡',
                'funding': 'æ•´ç‚¹è§¦å‘ï¼ˆä»…å½“æœ‰æŒä»“æ—¶ï¼‰ï¼Œå»¶è¿Ÿ30ç§’ï¼Œå¼ºåˆ¶é‡è¯•5æ¬¡',
                'data_type': 'è´¦æˆ·æ•°æ® + èµ„é‡‘è´¹æ•°æ®'
            },
            'endpoints': {
                'account': self.ACCOUNT_ENDPOINT,
                'funding_income': self.INCOME_ENDPOINT,
                'base_url': self.BASE_URL
            },
            'data_destination': 'private_data_processing.manager'
        }

        return status