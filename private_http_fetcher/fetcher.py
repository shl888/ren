"""
ç§äººHTTPæ•°æ®è·å–å™¨ - æƒé‡ç›‘æ§ä¿®æ­£ç‰ˆ
ä¸“æ³¨äºå‡†ç¡®è·å–æƒé‡ç›¸å…³æ•°æ®
"""
import asyncio
import logging
import time
import hmac
import hashlib
import urllib.parse
from datetime import datetime
from typing import Dict, Any, Optional
import aiohttp

logger = logging.getLogger(__name__)

class PrivateHTTPFetcher:
    """
    ç§äººHTTPæ•°æ®è·å–å™¨
    ä¸“æ³¨å‡†ç¡®è·å–æƒé‡æ•°æ®
    """
    
    def __init__(self):
        # ä¸private_ws_poolç›¸åŒçš„ç»“æ„
        self.brain_store = None          # DataManagerå®ä¾‹
        self.running = False
        
        # APIå‡­è¯
        self.api_key = None
        self.api_secret = None
        
        # ä»»åŠ¡ç®¡ç†
        self.scheduler_task = None
        self.fetch_tasks = []
        
        # Sessionå¤ç”¨
        self.session = None
        
        # çŠ¶æ€æ ‡å¿—
        self.account_fetched = False
        self.account_fetch_success = False
        
        # é‡è¯•ç­–ç•¥
        self.account_retry_delays = [10, 20, 40, 60]
        self.max_account_retries = 4
        
        # è‡ªé€‚åº”é¢‘ç‡æ§åˆ¶
        self.account_check_interval = 1
        self.account_high_freq = 1
        self.account_low_freq = 60
        self.has_position = False
        self.last_log_time = 0
        self.log_interval = 60
        
        # ğŸ”´ æ–°å¢ï¼šæƒé‡æ•°æ®è¿½è¸ª
        self.weight_data_history = []
        self.weight_debug_mode = True  # å¼€å¯è¯¦ç»†æƒé‡æ—¥å¿—
        
        # è¿æ¥è´¨é‡ç»Ÿè®¡
        self.quality_stats = {
            'account_fetch': {
                'total_attempts': 0,
                'success_attempts': 0,
                'last_success': None,
                'last_error': None,
                'success_rate': 100.0,
                'retry_count': 0,
                'weight_records': []  # æ–°å¢ï¼šè®°å½•æƒé‡æ•°æ®
            }
        }
        
        # å¸å®‰APIç«¯ç‚¹é…ç½®
        self.BASE_URL = "https://testnet.binancefuture.com"
        # self.BASE_URL = "https://fapi.binance.com"
        
        self.ACCOUNT_ENDPOINT = "/fapi/v3/account"
        
        # é…ç½®
        self.RECV_WINDOW = 5000
        
        # ç¯å¢ƒ
        self.environment = "testnet" if "testnet" in self.BASE_URL else "live"
        logger.info(f"ğŸ”— [HTTPè·å–å™¨] åˆå§‹åŒ–å®Œæˆï¼ˆç¯å¢ƒ: {self.environment} | æƒé‡è°ƒè¯•æ¨¡å¼å¼€å¯ï¼‰")
    
    async def start(self, brain_store):
        """
        å¯åŠ¨è·å–å™¨
        """
        logger.info(f"ğŸš€ [HTTPè·å–å™¨] æ­£åœ¨å¯åŠ¨ï¼ˆæƒé‡è°ƒè¯•æ¨¡å¼ï¼‰...")
        
        self.brain_store = brain_store
        self.running = True
        
        # åˆ›å»ºClientSession
        timeout = aiohttp.ClientTimeout(total=30)
        self.session = aiohttp.ClientSession(timeout=timeout)
        
        # åˆ›å»ºè°ƒåº¦ä»»åŠ¡
        self.scheduler_task = asyncio.create_task(self._controlled_scheduler())
        
        logger.info("âœ… [HTTPè·å–å™¨] è°ƒåº¦å™¨å·²å¯åŠ¨ï¼Œç­‰å¾…4åˆ†é’Ÿåæ‰§è¡Œè´¦æˆ·è·å–")
        return True
    
    async def _controlled_scheduler(self):
        """
        å—æ§è°ƒåº¦å™¨
        """
        try:
            # ========== ç¬¬ä¸€é˜¶æ®µï¼šç­‰å¾…4åˆ†é’Ÿ ==========
            logger.info("â³ [HTTPè·å–å™¨] ç¬¬ä¸€é˜¶æ®µï¼šç­‰å¾…4åˆ†é’Ÿ...")
            for i in range(240):
                if not self.running:
                    return
                if i % 60 == 0:
                    remaining = 240 - i
                    logger.info(f"â³ [HTTPè·å–å™¨] ç­‰å¾…ä¸­...å‰©ä½™{remaining}ç§’")
                await asyncio.sleep(1)
            
            logger.info("âœ… [HTTPè·å–å™¨] 4åˆ†é’Ÿç­‰å¾…å®Œæˆï¼Œå¼€å§‹è´¦æˆ·è·å–")
            
            # ========== ç¬¬äºŒé˜¶æ®µï¼šè·å–è´¦æˆ·èµ„äº§ ==========
            self.account_fetch_success = await self._fetch_account_with_retry()
            
            if self.account_fetch_success:
                logger.info("âœ… [HTTPè·å–å™¨] è´¦æˆ·è·å–æˆåŠŸ")
                
                # ========== ç¬¬ä¸‰é˜¶æ®µï¼šå¯åŠ¨è‡ªé€‚åº”é¢‘ç‡è·å– ==========
                logger.info("â³ [HTTPè·å–å™¨] è´¦æˆ·æˆåŠŸåå†·å´30ç§’...")
                await asyncio.sleep(30)
                
                account_task = asyncio.create_task(self._fetch_account_adaptive_freq())
                self.fetch_tasks.append(account_task)
                logger.info("âœ… [HTTPè·å–å™¨] è‡ªé€‚åº”é¢‘ç‡è´¦æˆ·æ•°æ®è·å–å·²å¯åŠ¨")
            else:
                logger.warning("âš ï¸ [HTTPè·å–å™¨] è´¦æˆ·è·å–å¤±è´¥ï¼Œä¸å¯åŠ¨åç»­ä»»åŠ¡")
                
        except asyncio.CancelledError:
            logger.info("ğŸ›‘ [HTTPè·å–å™¨] è°ƒåº¦å™¨è¢«å–æ¶ˆ")
        except Exception as e:
            logger.error(f"âŒ [HTTPè·å–å™¨] è°ƒåº¦å™¨å¼‚å¸¸: {e}")
    
    async def _fetch_account_with_retry(self):
        """
        è·å–è´¦æˆ·èµ„äº§ - é‡è¯•æœºåˆ¶
        """
        retry_count = 0
        total_attempts = 0
        
        # ç¬¬1æ¬¡å°è¯•
        logger.info(f"ğŸ’° [HTTPè·å–å™¨] è´¦æˆ·è·å–ç¬¬1æ¬¡å°è¯•...")
        result = await self._fetch_account_single()
        total_attempts += 1
        
        if result == 'PERMANENT_STOP':
            logger.error("ğŸš¨ [HTTPè·å–å™¨] é‡åˆ°ä¸å¯é€†é”™è¯¯ï¼Œåœæ­¢æ‰€æœ‰é‡è¯•")
            self.quality_stats['account_fetch']['retry_count'] = 0
            return False
        
        if result == True:
            self.quality_stats['account_fetch']['retry_count'] = 0
            return True
        
        # é‡è¯•
        while retry_count < self.max_account_retries and self.running:
            delay = self.account_retry_delays[retry_count]
            logger.info(f"â³ [HTTPè·å–å™¨] {delay}ç§’åé‡è¯•è´¦æˆ·è·å–ï¼ˆç¬¬{retry_count + 2}æ¬¡å°è¯•ï¼‰...")
            await asyncio.sleep(delay)
            
            logger.info(f"ğŸ’° [HTTPè·å–å™¨] è´¦æˆ·è·å–ç¬¬{retry_count + 2}æ¬¡å°è¯•...")
            result = await self._fetch_account_single()
            total_attempts += 1
            retry_count += 1
            
            if result == 'PERMANENT_STOP':
                logger.error(f"ğŸš¨ [HTTPè·å–å™¨] ç¬¬{retry_count}æ¬¡å°è¯•é‡åˆ°ä¸å¯é€†é”™è¯¯ï¼Œåœæ­¢é‡è¯•")
                self.quality_stats['account_fetch']['retry_count'] = retry_count
                return False
            
            if result == True:
                self.quality_stats['account_fetch']['retry_count'] = retry_count
                return True
        
        # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
        self.quality_stats['account_fetch']['retry_count'] = retry_count
        logger.error(f"âŒ [HTTPè·å–å™¨] è´¦æˆ·è·å–{total_attempts}æ¬¡å°è¯•å…¨éƒ¨å¤±è´¥")
        return False
    
    async def _fetch_account_single(self):
        """
        å•æ¬¡å°è¯•è·å–è´¦æˆ·èµ„äº§
        """
        try:
            self.quality_stats['account_fetch']['total_attempts'] += 1
            
            api_key, api_secret = await self._get_fresh_credentials()
            if not api_key or not api_secret:
                logger.warning("âš ï¸ [HTTPè·å–å™¨] å‡­è¯è¯»å–å¤±è´¥ï¼Œæœ¬æ¬¡å°è¯•è·³è¿‡")
                self.quality_stats['account_fetch']['last_error'] = "å‡­è¯è¯»å–å¤±è´¥"
                return False
            
            # è¯·æ±‚å‚æ•°
            params = {
                'timestamp': int(time.time() * 1000),
                'recvWindow': self.RECV_WINDOW
            }
            signed_params = self._sign_params(params, api_secret)
            url = f"{self.BASE_URL}{self.ACCOUNT_ENDPOINT}"
            headers = {'X-MBX-APIKEY': api_key}
            
            # ğŸ”´ è®°å½•è¯·æ±‚å¼€å§‹æ—¶é—´
            request_start = time.time()
            
            async with self.session.get(url, params=signed_params, headers=headers) as resp:
                # ğŸ”´ è·å–æ‰€æœ‰ç›¸å…³header
                all_headers = dict(resp.headers)
                
                # æ‰“å°æ‰€æœ‰å¯èƒ½ç›¸å…³çš„æƒé‡header
                logger.info("=" * 60)
                logger.info("âš–ï¸ [æƒé‡Headerå®Œæ•´åˆ—è¡¨]:")
                for key, value in sorted(all_headers.items()):
                    key_lower = key.lower()
                    if any(term in key_lower for term in ['weight', 'order', 'rate', 'limit']):
                        logger.info(f"  {key}: {value}")
                
                # ğŸ”´ é‡ç‚¹ç›‘æ§è¿™ä¸¤ä¸ªheader
                used_weight = resp.headers.get('X-MBX-USED-WEIGHT')
                used_weight_1m = resp.headers.get('X-MBX-USED-WEIGHT-1M')
                
                logger.info(f"ğŸ“Š [é‡ç‚¹ç›‘æ§]:")
                logger.info(f"  X-MBX-USED-WEIGHT (å•æ¬¡): {used_weight or 'æœªæ‰¾åˆ°'}")
                logger.info(f"  X-MBX-USED-WEIGHT-1M (ç´¯è®¡): {used_weight_1m or 'æœªæ‰¾åˆ°'}")
                
                # è®°å½•æƒé‡æ•°æ®
                weight_record = {
                    'timestamp': datetime.now().isoformat(),
                    'request_start': request_start,
                    'response_time': time.time(),
                    'used_weight': used_weight,
                    'used_weight_1m': used_weight_1m,
                    'all_headers': {k: v for k, v in all_headers.items() 
                                   if any(term in k.lower() for term in ['weight', 'order'])}
                }
                
                self.quality_stats['account_fetch']['weight_records'].append(weight_record)
                
                if resp.status == 200:
                    data = await resp.json()
                    await self._push_data('http_account', data)
                    
                    self.quality_stats['account_fetch']['success_attempts'] += 1
                    self.quality_stats['account_fetch']['last_success'] = datetime.now().isoformat()
                    self.quality_stats['account_fetch']['last_error'] = None
                    self.quality_stats['account_fetch']['success_rate'] = (
                        self.quality_stats['account_fetch']['success_attempts'] / 
                        self.quality_stats['account_fetch']['total_attempts'] * 100
                    )
                    
                    logger.info("âœ… [HTTPè·å–å™¨] è´¦æˆ·èµ„äº§è·å–æˆåŠŸï¼")
                    self.account_fetched = True
                    return True
                
                else:
                    error_text = await resp.text()
                    error_msg = f"HTTP {resp.status}: {error_text[:100]}"
                    self.quality_stats['account_fetch']['last_error'] = error_msg
                    
                    if resp.status == 418:
                        retry_after = int(resp.headers.get('Retry-After', 10))
                        logger.error(f"ğŸš¨ [HTTPè·å–å™¨] IPè¢«å°ç¦(418)ï¼Œéœ€ç­‰å¾…{retry_after}ç§’")
                        return 'PERMANENT_STOP'
                    
                    if resp.status == 401:
                        logger.error(f"ğŸš¨ [HTTPè·å–å™¨] APIå¯†é’¥æ— æ•ˆæˆ–æƒé™ä¸è¶³(401)")
                        return 'PERMANENT_STOP'
                    
                    if resp.status == 429:
                        retry_after = int(resp.headers.get('Retry-After', 60))
                        logger.warning(f"âš ï¸ [HTTPè·å–å™¨] è§¦å‘é¢‘ç‡é™åˆ¶(429)ï¼Œç­‰å¾…{retry_after}ç§’åé‡è¯•")
                        await asyncio.sleep(retry_after)
                        return False
                    
                    logger.error(f"âŒ [HTTPè·å–å™¨] è´¦æˆ·è¯·æ±‚å¤±è´¥ {error_msg}")
                    return False
                        
        except asyncio.TimeoutError:
            error_msg = "è¯·æ±‚è¶…æ—¶"
            self.quality_stats['account_fetch']['last_error'] = error_msg
            logger.error(f"â±ï¸ [HTTPè·å–å™¨] è´¦æˆ·è¯·æ±‚è¶…æ—¶")
            return False
        except Exception as e:
            error_msg = str(e)
            self.quality_stats['account_fetch']['last_error'] = error_msg
            logger.error(f"âŒ [HTTPè·å–å™¨] è·å–è´¦æˆ·å¼‚å¸¸: {e}")
            return False
    
    async def _fetch_account_adaptive_freq(self):
        """
        è‡ªé€‚åº”é¢‘ç‡è·å–è´¦æˆ·æ•°æ® - ä¿®å¤æƒé‡è·å–
        """
        request_count = 0
        last_weight_values = {}  # è®°å½•å†å²æƒé‡å€¼
        
        # åˆå§‹ç­‰å¾…
        await asyncio.sleep(30)
        
        while self.running:
            try:
                request_count += 1
                
                api_key, api_secret = await self._get_fresh_credentials()
                if not api_key or not api_secret:
                    logger.warning("âš ï¸ [HTTPè·å–å™¨] è´¦æˆ·è¯·æ±‚-å‡­è¯è¯»å–å¤±è´¥")
                    await asyncio.sleep(self.account_check_interval)
                    continue
                
                # è¯·æ±‚å‚æ•°
                params = {
                    'timestamp': int(time.time() * 1000),
                    'recvWindow': self.RECV_WINDOW
                }
                signed_params = self._sign_params(params, api_secret)
                url = f"{self.BASE_URL}{self.ACCOUNT_ENDPOINT}"
                headers = {'X-MBX-APIKEY': api_key}
                
                # ğŸ”´ è®°å½•è¯·æ±‚å¼€å§‹æ—¶é—´
                request_start = time.time()
                request_start_str = datetime.fromtimestamp(request_start).strftime('%H:%M:%S.%f')[:-3]
                
                async with self.session.get(url, params=signed_params, headers=headers) as resp:
                    # ğŸ”´ è·å–æ‰€æœ‰header
                    all_headers = dict(resp.headers)
                    
                    # ğŸ”´ ç²¾å‡†è·å–æƒé‡header
                    used_weight = resp.headers.get('X-MBX-USED-WEIGHT')
                    used_weight_1m = resp.headers.get('X-MBX-USED-WEIGHT-1M')
                    
                    # è®°å½•å“åº”æ—¶é—´
                    response_time = time.time()
                    response_str = datetime.fromtimestamp(response_time).strftime('%H:%M:%S.%f')[:-3]
                    response_delay = response_time - request_start
                    
                    # ğŸ”´ ç²¾ç¡®æ‰“å°æƒé‡ä¿¡æ¯
                    logger.info("=" * 60)
                    logger.info(f"ğŸ•’ [æ—¶é—´æˆ³] è¯·æ±‚: {request_start_str} | å“åº”: {response_str} | å»¶è¿Ÿ: {response_delay:.3f}s")
                    logger.info(f"ğŸ“Š [æƒé‡æ•°æ®] è¯·æ±‚#{request_count}:")
                    logger.info(f"  X-MBX-USED-WEIGHT: {used_weight or 'æœªæ‰¾åˆ°'}")
                    logger.info(f"  X-MBX-USED-WEIGHT-1M: {used_weight_1m or 'æœªæ‰¾åˆ°'}")
                    
                    # è®°å½•å†å²æ•°æ®
                    if used_weight_1m:
                        weight_val = int(used_weight_1m)
                        last_weight_values[request_count] = {
                            'timestamp': request_start,
                            'weight': weight_val,
                            'request_num': request_count
                        }
                        
                        # ğŸ”´ åˆ†æå˜åŒ–
                        if len(last_weight_values) >= 2:
                            prev_req = request_count - 1
                            if prev_req in last_weight_values:
                                prev_weight = last_weight_values[prev_req]['weight']
                                time_diff = request_start - last_weight_values[prev_req]['timestamp']
                                weight_diff = weight_val - prev_weight
                                
                                logger.info(f"ğŸ“ˆ [å˜åŒ–åˆ†æ] é—´éš”: {time_diff:.1f}s | "
                                          f"æƒé‡å˜åŒ–: {weight_diff:+d} | "
                                          f"({prev_weight} â†’ {weight_val})")
                    
                    if resp.status == 200:
                        data = await resp.json()
                        
                        # æ£€æŸ¥æŒä»“
                        positions = data.get('positions', [])
                        has_position_now = False
                        for pos in positions:
                            position_amt = float(pos.get('positionAmt', '0'))
                            if position_amt != 0:
                                has_position_now = True
                                break
                        
                        # é¢‘ç‡è°ƒæ•´
                        if has_position_now:
                            if not self.has_position:
                                logger.info(f"ğŸš€ [HTTPè·å–å™¨] æ£€æµ‹åˆ°æŒä»“ï¼Œåˆ‡æ¢é«˜é¢‘æ¨¡å¼ï¼ˆ1ç§’ï¼‰")
                            self.account_check_interval = self.account_high_freq
                            self.has_position = True
                        else:
                            if self.has_position:
                                logger.info(f"ğŸ’¤ [HTTPè·å–å™¨] æ£€æµ‹åˆ°æ¸…ä»“ï¼Œåˆ‡æ¢ä½é¢‘æ¨¡å¼ï¼ˆ60ç§’ï¼‰")
                            self.account_check_interval = self.account_low_freq
                            self.has_position = False
                        
                        # æ§åˆ¶æ—¥å¿—é¢‘ç‡
                        current_time = time.time()
                        if current_time - self.last_log_time >= self.log_interval:
                            if has_position_now:
                                positions_count = len([p for p in positions if float(p.get('positionAmt', '0')) != 0])
                                logger.info(f"ğŸ“Š [HTTPè·å–å™¨] å½“å‰æŒä»“{positions_count}ä¸ª | é«˜é¢‘æ¨¡å¼ | è¯·æ±‚æ¬¡æ•°:{request_count}")
                            else:
                                logger.info(f"ğŸ“Š [HTTPè·å–å™¨] å½“å‰æ— æŒä»“ | ä½é¢‘æ¨¡å¼ | è¯·æ±‚æ¬¡æ•°:{request_count}")
                            self.last_log_time = current_time
                        
                        await self._push_data('http_account', data)
                        
                        # æ›´æ–°ç»Ÿè®¡
                        self.quality_stats['account_fetch']['success_attempts'] += 1
                        self.quality_stats['account_fetch']['total_attempts'] += 1
                        self.quality_stats['account_fetch']['last_success'] = datetime.now().isoformat()
                        self.quality_stats['account_fetch']['success_rate'] = (
                            self.quality_stats['account_fetch']['success_attempts'] / 
                            self.quality_stats['account_fetch']['total_attempts'] * 100
                        )
                        
                        await asyncio.sleep(self.account_check_interval)
                        
                    else:
                        error_text = await resp.text()
                        error_msg = f"HTTP {resp.status}: {error_text[:100]}"
                        self.quality_stats['account_fetch']['last_error'] = error_msg
                        logger.error(f"âŒ [HTTPè·å–å™¨] è´¦æˆ·è¯·æ±‚å¤±è´¥ {error_msg}")
                        
                        if resp.status in [418, 401]:
                            retry_after = int(resp.headers.get('Retry-After', 3600))
                            logger.error(f"ğŸš¨ [HTTPè·å–å™¨] è´¦æˆ·è¯·æ±‚è§¦å‘ä¸¥é‡é”™è¯¯({resp.status})ï¼Œç­‰å¾…{retry_after}ç§’åæ°¸ä¹…åœæ­¢")
                            await asyncio.sleep(retry_after)
                            break
                        
                        if resp.status == 429:
                            retry_after = int(resp.headers.get('Retry-After', 60))
                            logger.warning(f"âš ï¸ [HTTPè·å–å™¨] è´¦æˆ·è¯·æ±‚è§¦å‘é¢‘ç‡é™åˆ¶(429)ï¼Œç­‰å¾…{retry_after}ç§’")
                            await asyncio.sleep(retry_after)
                        else:
                            await asyncio.sleep(self.account_check_interval)
                                
            except asyncio.CancelledError:
                break
            except Exception as e:
                error_msg = str(e)
                self.quality_stats['account_fetch']['last_error'] = error_msg
                logger.error(f"âŒ [HTTPè·å–å™¨] è´¦æˆ·å¾ªç¯å¼‚å¸¸: {e}")
                await asyncio.sleep(self.account_check_interval)
    
    async def _get_fresh_credentials(self):
        """è¯»å–æ–°é²œå‡­è¯"""
        try:
            if not self.brain_store:
                return None, None
            creds = await self.brain_store.get_api_credentials('binance')
            if creds and creds.get('api_key') and creds.get('api_secret'):
                return creds['api_key'], creds['api_secret']
        except Exception as e:
            logger.error(f"âŒ [HTTPè·å–å™¨] è¯»å–å‡­è¯å¤±è´¥: {e}")
        return None, None
    
    def _sign_params(self, params: Dict, api_secret: str) -> Dict:
        """ç”Ÿæˆç­¾å"""
        query = urllib.parse.urlencode(params)
        signature = hmac.new(api_secret.encode(), query.encode(), hashlib.sha256).hexdigest()
        params['signature'] = signature
        return params
    
    async def _push_data(self, data_type: str, raw_data: Dict):
        """æ¨é€æ•°æ®"""
        try:
            from private_data_processing.manager import receive_private_data
            await receive_private_data({
                'exchange': 'binance',
                'data_type': data_type,
                'data': raw_data,
                'timestamp': datetime.now().isoformat(),
                'source': 'http_fetcher'
            })
        except ImportError as e:
            logger.error(f"âŒ [HTTPè·å–å™¨] æ— æ³•å¯¼å…¥ç§äººæ•°æ®å¤„ç†æ¨¡å—: {e}")
        except Exception as e:
            logger.error(f"âŒ [HTTPè·å–å™¨] æ¨é€æ•°æ®å¤±è´¥: {e}")
    
    async def shutdown(self):
        """å…³é—­è·å–å™¨"""
        logger.info("ğŸ›‘ [HTTPè·å–å™¨] æ­£åœ¨å…³é—­...")
        self.running = False
        
        if self.scheduler_task:
            self.scheduler_task.cancel()
            try:
                await self.scheduler_task
            except asyncio.CancelledError:
                pass
        
        for task in self.fetch_tasks:
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass
        
        if self.session:
            await self.session.close()
            logger.info("âœ… [HTTPè·å–å™¨] HTTPä¼šè¯å·²å…³é—­")
        
        logger.info("âœ… [HTTPè·å–å™¨] å·²å…³é—­")
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–çŠ¶æ€ä¿¡æ¯"""
        status = {
            'timestamp': datetime.now().isoformat(),
            'running': self.running,
            'account_fetched': self.account_fetched,
            'account_fetch_success': self.account_fetch_success,
            'environment': self.environment,
            'adaptive_frequency': {
                'current_interval': self.account_check_interval,
                'has_position': self.has_position,
                'high_freq': self.account_high_freq,
                'low_freq': self.account_low_freq
            },
            'quality_stats': self.quality_stats,
            'weight_debug_mode': self.weight_debug_mode,
            'schedule': {
                'account': 'å¯åŠ¨å4åˆ†é’Ÿå¼€å§‹ï¼Œ5æ¬¡æŒ‡æ•°é€€é¿é‡è¯•ï¼Œç„¶åè‡ªé€‚åº”é¢‘ç‡',
                'data_type': 'ä»…è·å–è´¦æˆ·æ•°æ®ï¼ˆåŒ…å«æŒä»“ä¿¡æ¯ï¼‰'
            },
            'endpoints': {
                'account': self.ACCOUNT_ENDPOINT,
                'base_url': self.BASE_URL
            },
            'data_destination': 'private_data_processing.manager'
        }
        
        return status